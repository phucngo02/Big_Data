{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1NZtSKF0y-TrP6gR9oO7LlxadZ5XFGyDX","authorship_tag":"ABX9TyMtXJjxaQqowu1PU75O8NeR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install fastBPE\n","!pip install fairseq\n","!pip install vncorenlp"],"metadata":{"id":"sruGiR046G9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","path = '/content/drive/MyDrive/ProjectBigData/code/PhoBERT'\n","os.chdir(path)"],"metadata":{"id":"m3cPrMuEADG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","!tar -xzvf PhoBERT_base_transformers.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hyi0VgkAAURA","executionInfo":{"status":"ok","timestamp":1689432253592,"user_tz":-420,"elapsed":42345,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"801b049e-5564-4e59-bd08-cbd3cf0a8c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-07-15 14:43:31--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 18.64.174.107, 18.64.174.113, 18.64.174.104, ...\n","Connecting to public.vinai.io (public.vinai.io)|18.64.174.107|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 322405979 (307M) [application/x-tar]\n","Saving to: ‚ÄòPhoBERT_base_transformers.tar.gz‚Äô\n","\n","PhoBERT_base_transf 100%[===================>] 307.47M  17.7MB/s    in 20s     \n","\n","2023-07-15 14:43:53 (15.5 MB/s) - ‚ÄòPhoBERT_base_transformers.tar.gz‚Äô saved [322405979/322405979]\n","\n","PhoBERT_base_transformers/\n","PhoBERT_base_transformers/config.json\n","PhoBERT_base_transformers/bpe.codes\n","PhoBERT_base_transformers/model.bin\n","PhoBERT_base_transformers/dict.txt\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROg86Qis5xoN"},"outputs":[],"source":["!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/\n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"]},{"cell_type":"code","source":["import pandas as pd\n","from tqdm import tqdm\n","tqdm.pandas()\n","import json\n","import numpy as np\n","import pickle\n","import os\n","import torch\n","##########\n","\n","def seed_everything(SEED):\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.backends.cudnn.deterministic = True\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))"],"metadata":{"id":"7mu2tZ3w7dzu","executionInfo":{"status":"ok","timestamp":1689437208562,"user_tz":-420,"elapsed":7157,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from vncorenlp import VnCoreNLP\n","rdrsegmenter = VnCoreNLP(path+'/vncorenlp/VnCoreNLP-1.1.1.jar', annotators=\"wseg\", max_heap_size='-Xmx500m')\n","from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes',\n","    default=path+\"/PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(path+\"/PhoBERT_base_transformers/dict.txt\")"],"metadata":{"id":"scBtlPUc6Zil","executionInfo":{"status":"ok","timestamp":1689437229339,"user_tz":-420,"elapsed":17808,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","import pandas as pd\n","from tqdm import tqdm\n","tqdm.pandas()\n","from torch import nn\n","import json\n","import numpy as np\n","import pickle\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold,train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n","from transformers import *\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.utils.data\n","import torch.nn.functional as F\n","import argparse\n","from transformers.modeling_utils import *"],"metadata":{"id":"tQ9M2ddSA4qZ","executionInfo":{"status":"ok","timestamp":1689437245757,"user_tz":-420,"elapsed":16420,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7422371f-eea8-4fa2-a9d9-6a2496578490"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n","  warnings.warn(\n","Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n","pip install xformers.\n"]}]},{"cell_type":"code","source":["class RobertaForReINTEL(BertPreTrainedModel):\n","   config_class = RobertaConfig\n","   ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = {\n","    'roberta-base': \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin\",\n","    'roberta-large': \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin\",\n","    'roberta-large-mnli': \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin\",\n","    'distilroberta-base': \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin\",\n","    'roberta-base-openai-detector': \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin\",\n","    'roberta-large-openai-detector': \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin\",\n","}\n","\n","   pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP\n","   base_model_prefix = \"roberta\"\n","   def __init__(self, config):\n","       super(RobertaForReINTEL, self).__init__(config)\n","       self.num_labels = config.num_labels\n","       self.roberta = RobertaModel(config)\n","       self.qa_outputs = nn.Linear(4*config.hidden_size, self.num_labels)\n","\n","       self.init_weights()\n","\n","   def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n","                start_positions=None, end_positions=None):\n","\n","       outputs = self.roberta(input_ids,\n","                            attention_mask=attention_mask,\n","                            position_ids=position_ids,\n","                            head_mask=head_mask)\n","       cls_output = torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1)\n","       logits = self.qa_outputs(cls_output)\n","       return logits"],"metadata":{"id":"CaUzQNL5BSRA","executionInfo":{"status":"ok","timestamp":1689437245758,"user_tz":-420,"elapsed":5,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n","config = RobertaConfig.from_pretrained(\n","    path+\"/PhoBERT_base_transformers/config.json\",\n","    output_hidden_states=True,\n","    num_labels=1\n",")\n","model_bert = RobertaForReINTEL.from_pretrained(path+'/PhoBERT_base_transformers/model.bin', config=config)"],"metadata":{"id":"DXj-3qLIBUBR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689437257780,"user_tz":-420,"elapsed":12026,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"4cd9163f-2ff0-4820-f66b-12dadde8d451"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/drive/MyDrive/ProjectBigData/code/PhoBERT/PhoBERT_base_transformers/config.json\n","You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"eos_token_ids\": 0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 258,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.30.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 64001\n","}\n","\n","loading weights file /content/drive/MyDrive/ProjectBigData/code/PhoBERT/PhoBERT_base_transformers/model.bin\n","Some weights of the model checkpoint at /content/drive/MyDrive/ProjectBigData/code/PhoBERT/PhoBERT_base_transformers/model.bin were not used when initializing RobertaForReINTEL: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForReINTEL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForReINTEL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForReINTEL were not initialized from the model checkpoint at /content/drive/MyDrive/ProjectBigData/code/PhoBERT/PhoBERT_base_transformers/model.bin and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["if torch.cuda.device_count():\n","    print(f\"Training using {torch.cuda.device_count()} gpus\")\n","    model_bert = nn.DataParallel(model_bert)\n","    tsfm = model_bert.module.roberta\n","else:\n","    tsfm = model_bert.roberta"],"metadata":{"id":"MPv-S06nBbk2","executionInfo":{"status":"ok","timestamp":1689437257781,"user_tz":-420,"elapsed":19,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"204056c9-7b3e-4538-d2a9-105fa79ea3a5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Training using 1 gpus\n"]}]},{"cell_type":"code","source":["kmax_sequence_length= 258\n","kbatch_size= 32\n","kaccumulation_steps= 5\n","kepochs= 5\n","kfold= 0\n","kseed= 42\n","klr= 2e-5"],"metadata":{"id":"rd3g42YLBdrc","executionInfo":{"status":"ok","timestamp":1689437482254,"user_tz":-420,"elapsed":1,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/ProjectBigData/Data/comb_extraSNS_ReINTEL.csv')\n","# df = df.dropna(subset=['post_message'])\n","train_df, test = train_test_split(df, test_size=0.2, random_state=123)\n","print(train_df)"],"metadata":{"id":"PAjIbt62BwvI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689437272154,"user_tz":-420,"elapsed":4673,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"3ceb4c93-85ca-42da-d05f-fb1f19733ba4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["                                           post_message  label\n","6441  H√¥m_nay . ch√∫ng_ta n√™n d√†nh 1 ph√∫t th√¥i ƒë·ªÉ xem...      0\n","3844  Ch·ªß_t·ªãch H√†_N·ªôi cho bi·∫øt . trong cu·ªôc h·ªçp Ban ...      0\n","3479  T·ªîN_TH∆Ø∆†NG PH·ªîI C·ª¶A B·ªÜNH_NH√ÇN ƒê√É CHI·∫æM 90% üõå T...      0\n","5352  ‚ú®‚ú®‚ú® Em chia_s·∫ª ch√∫t v·ªÅ ng∆∞·ªùi v·ª´a b·ªã nhi·ªÖm Viru...      1\n","4632  Ng√†y 7/3 . Sputnik ƒë∆∞a tin 3 th√†nh_vi√™n cao_c·∫•...      0\n","...                                                 ...    ...\n","4060  üì£ BN329 KH·ªéI COVID-19 ; S·ªê NG∆Ø·ªúI C√ÅCH_LY C√íN 6...      0\n","1346  Sau g·∫ßn m·ªôt th√°ng im h∆°i l·∫∑ng ti·∫øng , t·ªëi 12 /...      0\n","3454  C√¥ng_an ƒê·ªìng_Nai x√°c_ƒë·ªãnh m·ªôt ph·ª•_n·ªØ ƒë·ªãa_ph∆∞∆°n...      0\n","7533  N·ªØ ti·∫øp_vi√™n g·ªëc Hoa b·ªã ch·ª•p tr·ªôm g√¢y s·ªët m·∫°ng...      0\n","3582  ƒê·∫øn nay ƒë√£ g·∫ßn n·ª≠a th√°ng k·ªÉ t·ª´ khi x·∫£y ra v·ª•_v...      0\n","\n","[6087 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["train_df = train_df[['post_message','label']].fillna('none')\n","train_df.post_message = train_df.post_message.progress_apply(lambda x: ' '.join([' '.join(sent) for sent in rdrsegmenter.tokenize(x)]))\n","y = train_df.label.values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5od55X9aBrpu","executionInfo":{"status":"ok","timestamp":1689437552518,"user_tz":-420,"elapsed":49212,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"174007b5-1839-46cf-8403-6ea4963824a9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6087/6087 [00:51<00:00, 118.45it/s]\n"]}]},{"cell_type":"code","source":["print(train_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCFRoAbpQEMl","executionInfo":{"status":"ok","timestamp":1689436310324,"user_tz":-420,"elapsed":302,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"2e6c4034-78d6-46ba-84fd-917a8f367e77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(6087, 2)\n"]}]},{"cell_type":"code","source":["def convert_lines(df, vocab, bpe, max_sequence_length):\n","    outputs = np.zeros((len(df), max_sequence_length))\n","\n","    cls_id = 0\n","    eos_id = 2\n","    pad_id = 1\n","\n","\n","    for idx, row in tqdm(df.iterrows(), total=len(df)):\n","        if idx < len(df):\n","            subwords = bpe.encode(' '+row.post_message+' ')\n","            input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n","            if len(input_ids) > max_sequence_length:\n","                input_ids = input_ids[:max_sequence_length]\n","                input_ids[-1] = eos_id\n","            else:\n","                input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n","            outputs[idx,:] = np.array(input_ids)\n","        # print(idx, row)\n","    return outputs\n","\n","X_train = convert_lines(train_df, vocab, bpe, kmax_sequence_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdnEcn9xMesh","executionInfo":{"status":"ok","timestamp":1689437880915,"user_tz":-420,"elapsed":12194,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"c963fa1f-10bc-4569-cf75-383afe94fe57"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6087/6087 [00:12<00:00, 490.37it/s]\n"]}]},{"cell_type":"code","source":["param_optimizer = list(model_bert.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","num_train_optimization_steps = int(kepochs*len(train_df)/kbatch_size/kaccumulation_steps)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=klr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n","scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNn-ZTWMRKNy","executionInfo":{"status":"ok","timestamp":1689438105282,"user_tz":-420,"elapsed":2,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"8263b1df-4ede-4cf7-bc1c-219ae2dd7b9e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(X_train, y))\n","import os\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","for fold, (train_idx, val_idx) in enumerate(splits):\n","    if fold != kfold:\n","      continue\n","    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train[train_idx],dtype=torch.long), torch.tensor(y[train_idx],dtype=torch.long))\n","    valid_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train[val_idx],dtype=torch.long), torch.tensor(y[val_idx],dtype=torch.long))\n","    tq = tqdm(range(kepochs + 1))\n","    for child in tsfm.children():\n","        for param in child.parameters():\n","            if not param.requires_grad:\n","                print(\"whoopsies\")\n","            param.requires_grad = False\n","    frozen = True\n","    for epoch in tq:\n","\n","        if epoch > 0 and frozen:\n","            for child in tsfm.children():\n","                for param in child.parameters():\n","                    param.requires_grad = True\n","            frozen = False\n","            del scheduler0\n","            torch.cuda.empty_cache()\n","\n","        val_preds = None\n","        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=kbatch_size, shuffle=True)\n","        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=kbatch_size, shuffle=False)\n","        avg_loss = 0.\n","        avg_accuracy = 0.\n","\n","        optimizer.zero_grad()\n","        pbar = tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n","        for i,(x_batch, y_batch) in pbar:\n","            model_bert.train()\n","            y_pred = model_bert(x_batch.cuda(), attention_mask=(x_batch>0).cuda())\n","            loss =  F.binary_cross_entropy_with_logits(y_pred.view(-1).cuda(),y_batch.float().cuda())\n","            loss = loss.mean()\n","            loss.backward()\n","            if i % kaccumulation_steps == 0 or i == len(pbar) - 1:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                if not frozen:\n","                    scheduler.step()\n","                else:\n","                    scheduler0.step()\n","            lossf = loss.item()\n","            pbar.set_postfix(loss = lossf)\n","            avg_loss += loss.item() / len(train_loader)\n","\n","        model_bert.eval()\n","        pbar = tqdm(enumerate(valid_loader),total=len(valid_loader),leave=False)\n","        for i,(x_batch, y_batch) in pbar:\n","            y_pred = model_bert(x_batch.cuda(), attention_mask=(x_batch>0).cuda())\n","            y_pred = y_pred.squeeze().detach().cpu().numpy()\n","            val_preds = np.atleast_1d(y_pred) if val_preds is None else np.concatenate([val_preds, np.atleast_1d(y_pred)])\n","        val_preds = sigmoid(val_preds)\n","        score = f1_score(y[val_idx], val_preds > 0.5)\n","        print(f\"\\nAUC = {roc_auc_score(y[val_idx], val_preds):.4f}, F1 score @0.5 = {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l8ijt9AmROTH","executionInfo":{"status":"error","timestamp":1689438109091,"user_tz":-420,"elapsed":8,"user":{"displayName":"Qu√° Nguy·ªÖn","userId":"14480045489611476895"}},"outputId":"6f558c40-744b-410f-f573-77febc8e29e4"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/6 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n","whoopsies\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/153 [00:00<?, ?it/s]\u001b[A\n","  0%|          | 0/6 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-d14d7011c00b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmodel_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}]}]}